{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773b1cee",
   "metadata": {},
   "source": [
    "## 3. Cora dataset\n",
    "***\n",
    "One of the well-known categories of machine learning problems is “supervised learning”. In supervised learning, we are given some information called “input” features about certain objects. For each object, we are also given an “output” or target variable that we are trying to predict about. Our goal is to learn the mapping between the features and the target variable. Typically, there is a portion of data where both input features and target variables are available. This portion of the dataset is called the training set. There is also typically another portion of the dataset where the target variable is missing and we want to predict it. This portion is called the “test set”. When the target variable can take on a finite number of discrete values, we call the problem at hand a “classification” problem. In this project, we are trying to solve a classification problem in settings where some additional information is provided in the form of “graph structure”. In this project we work with “Cora” dataset. Cora consists of a set of 2708 documents that are Machine Learning related papers. Each documents is labeled with one of the following seven classes: Case Based, Genetic Algorithms, Neural Networks, Probabilistic Methods, Reinforcement Learning, Rule Learning, Theory. For each class, only 20 documents are labeled (a total of 140 for the seven classes). We refer to them as “seed” documents. Each document comes with a set of features about its text content. These features are occurrences of a selection of 1433 words in the vocabulary. We are also given an undirected graph where each node is a document and each edge represents a citation. There are a total of 5429 edges. Our goal is to use the hints from text features as well as from graph connections to classify (assign labels to) these documents. To solve this problem for Cora dataset, we pursue three parallel ideas. Implement each idea and compare.\n",
    "\n",
    "> Ans: In terms of accuracy, the rank of models of different ideas will be Idea 1 > Idea 3 > Idea 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd58b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import to_networkx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:2\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6e12d",
   "metadata": {},
   "source": [
    "### Load Cora Dataset\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4045f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root=\"./data/Cora\", name=\"Cora\", transform=NormalizeFeatures())\n",
    "\n",
    "data = dataset[0]\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"======================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "\n",
    "print(f\"Number of nodes: {data.num_nodes}\")\n",
    "print(f\"Number of edges: {data.num_edges}\")\n",
    "print(f\"Average node degree: {data.num_edges / data.num_nodes:.2f}\")\n",
    "print(f\"Number of training nodes: {data.train_mask.sum()}\")\n",
    "print(f\"Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}\")\n",
    "print(f\"Contains isolated nodes: {data.contains_isolated_nodes()}\")\n",
    "print(f\"Contains self-loops: {data.contains_self_loops()}\")\n",
    "print(f\"Is undirected: {data.is_undirected()}\")\n",
    "\n",
    "data = data.to(device)\n",
    "G = to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e0938",
   "metadata": {},
   "source": [
    "#### QUESTION 23: Idea 1\n",
    "Use Graph Convolutional Networks [1]. What hyperparameters do you choose to get the optimal performance? How many layers did you choose?\n",
    "\n",
    "Ref: [1] Kipf, Thomas N., and Max Welling. “Semi-supervised classification with graph convolutional networks.” arXiv preprint arXiv:1609.02907 (2016).\n",
    "\n",
    "> Ans: A three-layer GCN with `hidden_dim=32`, `lr=0.01`, and `weight_decay=0.0005` has the best accuracy of 0.818."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f5458e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try: hidden_dim=16, lr=0.01, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.79600\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.79400\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.70000\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.78100\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.76900\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.76400\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.78500\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.77900\n",
      "\n",
      "Try: hidden_dim=16, lr=0.01, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.66000\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.69800\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.42100\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.37100\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.64200\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.36300\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.44500\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.60000\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.52900\n",
      "\n",
      "Try: hidden_dim=16, lr=0.001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.56300\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.47300\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.55600\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.52500\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.44700\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.38900\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.46100\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.56100\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.12700\n",
      "\n",
      "Try: hidden_dim=16, lr=0.0001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.52600\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80700\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.81800\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.71300\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80500\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.78000\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.72500\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80500\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.77400\n",
      "\n",
      "Try: hidden_dim=32, lr=0.01, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.76600\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.71500\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.57200\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.66800\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.78300\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.69000\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.74100\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.76100\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.75700\n",
      "\n",
      "Try: hidden_dim=32, lr=0.001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.69300\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.61000\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.60600\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.50000\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.67100\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.40600\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.71000\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.54700\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.59400\n",
      "\n",
      "Try: hidden_dim=32, lr=0.0001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.50500\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.80100\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.80200\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80700\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.79400\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.76400\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.80300\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.78300\n",
      "\n",
      "Try: hidden_dim=64, lr=0.01, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.75200\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.74800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.76900\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.79300\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.75800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.79800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.76700\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0, n_layer=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model with best valid accuracy:  0.78000\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.79300\n",
      "\n",
      "Try: hidden_dim=64, lr=0.001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.78800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0.0005, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.69500\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0.0005, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.73500\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0.0005, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.63800\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=5e-05, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.63900\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=5e-05, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.66600\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=5e-05, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.60900\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0, n_layer=2\n",
      "Test accuracy of model with best valid accuracy:  0.75100\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0, n_layer=3\n",
      "Test accuracy of model with best valid accuracy:  0.51600\n",
      "\n",
      "Try: hidden_dim=64, lr=0.0001, weight_decay=0, n_layer=4\n",
      "Test accuracy of model with best valid accuracy:  0.67700\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.818, {'hidden_dim': 32, 'lr': 0.01, 'weight_decay': 0.0005, 'n_layer': 3})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TwoLayerGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ThreeLayerGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FourLayerGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv4 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_and_get_best_score(hidden_dim, lr, weight_decay, n_layer, verbose=False):\n",
    "    print(f\"Try: {hidden_dim=}, {lr=}, {weight_decay=}, {n_layer=}\")\n",
    "    n_epoch = 100\n",
    "    model_map = {2: TwoLayerGCN, 3: ThreeLayerGCN, 4: FourLayerGCN}\n",
    "    model = model_map[n_layer](dataset.num_features, hidden_dim, dataset.num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_valid_acc = 0\n",
    "    best_test_acc = None\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "        correct = (pred[data.train_mask] == data.y[data.train_mask]).sum()\n",
    "        train_acc = int(correct) / int(data.train_mask.sum())\n",
    "        correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "        valid_acc = int(correct) / int(data.val_mask.sum())\n",
    "        correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "        test_acc = int(correct) / int(data.test_mask.sum())\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1}:\")\n",
    "            print(f\"  - Train Accuracy: {train_acc: .5f}\")\n",
    "            print(f\"  - Valid Accuracy: {valid_acc: .5f}\")\n",
    "            print(f\"  - Test Accuracy: {test_acc: .5f}\")\n",
    "\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_test_acc = test_acc\n",
    "\n",
    "    print(f\"Test accuracy of model with best valid accuracy: {best_test_acc: .5f}\\n\")\n",
    "    return best_test_acc\n",
    "\n",
    "\n",
    "hidden_dims = [16, 32, 64]\n",
    "lrs = [1e-2, 1e-3, 1e-4]\n",
    "weight_decays = [5e-4, 5e-5, 0]\n",
    "n_layers = [2, 3, 4]\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for hidden_dim in hidden_dims:\n",
    "    for lr in lrs:\n",
    "        for weight_decay in weight_decays:\n",
    "            for n_layer in n_layers:\n",
    "                score = train_and_get_best_score(hidden_dim, lr, weight_decay, n_layer)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = {\n",
    "                        \"hidden_dim\": hidden_dim,\n",
    "                        \"lr\": lr,\n",
    "                        \"weight_decay\": weight_decay,\n",
    "                        \"n_layer\": n_layer,\n",
    "                    }\n",
    "\n",
    "best_score, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5f88a",
   "metadata": {},
   "source": [
    "#### QUESTION 24: Idea 2\n",
    "Extract structure-based node features using Node2Vec [2]. Briefly describe how Node2Vec finds node features. Choose your desired classifier (one of SVM, Neural Network, or Random Forest) and classify the documents using only Node2Vec (graph structure) features. Now classify the documents using only the 1433-dimensional text features. Which one outperforms? Why do you think this is the case? Combine the Node2Vec and text features and train your classifier on the combined features. What is the best classification accuracy you get (in terms of the percentage of test documents correctly classified)?\n",
    "\n",
    "> Ans: Node2Vec first runs several biased random walks on the graph. Then it takes random walks as sentences to feed into the Word2Vec model. As we can see in the result below, no matter what classifier we use, ones trained on text features outperform those trained on Node2Vec features. We think that it is because text features should contain more useful information for a content-classifying task.\n",
    ">\n",
    "> Then, if we combine both features, Random Forest gives the best accuracy of 0.305. However, the performance is still much worse than the model trained on text features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0b25da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b616859ba0d7455780366406d5c6675b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 2): 100%|██████████| 7/7 [00:12<00:00,  1.82s/it]]\n",
      "Generating walks (CPU: 1): 100%|██████████| 7/7 [00:13<00:00,  1.94s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 7/7 [00:13<00:00,  1.89s/it]]\n",
      "Generating walks (CPU: 6): 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n",
      "Generating walks (CPU: 7): 100%|██████████| 6/6 [00:11<00:00,  1.89s/it]]\n",
      "Generating walks (CPU: 8): 100%|██████████| 6/6 [00:11<00:00,  1.86s/it]\n",
      "Generating walks (CPU: 5): 100%|██████████| 6/6 [00:13<00:00,  2.19s/it]]\n",
      "Generating walks (CPU: 4): 100%|██████████| 7/7 [00:13<00:00,  1.98s/it]]\n",
      "Generating walks (CPU: 9): 100%|██████████| 6/6 [00:12<00:00,  2.01s/it]]\n",
      "Generating walks (CPU: 10): 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n",
      "Generating walks (CPU: 12): 100%|██████████| 6/6 [00:11<00:00,  1.90s/it]\n",
      "Generating walks (CPU: 11): 100%|██████████| 6/6 [00:12<00:00,  2.02s/it]\n",
      "Generating walks (CPU: 13): 100%|██████████| 6/6 [00:11<00:00,  1.96s/it]\n",
      "Generating walks (CPU: 14): 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n",
      "Generating walks (CPU: 15): 100%|██████████| 6/6 [00:11<00:00,  1.90s/it]\n",
      "Generating walks (CPU: 16): 100%|██████████| 6/6 [00:11<00:00,  1.87s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2708, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node2vec = Node2Vec(G, dimensions=128, walk_length=80, num_walks=100, p=1, q=1, workers=16)\n",
    "model = node2vec.fit(window=10, min_count=0, sg=1, epochs=10, workers=16)\n",
    "node_embeddings = model.wv.vectors\n",
    "node_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5460eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcfdcff2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf_name='SVM':\n",
      "  - Node2Vec:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.15700\n",
      "    - F1 score (test): 0.13597\n",
      "  - Text:\n",
      "    - Accuracy (train): 0.99286\n",
      "    - F1 score (train): 0.99285\n",
      "    - Accuracy (test): 0.58400\n",
      "    - F1 score (test): 0.56144\n",
      "  - Node2Vec + Text:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.16500\n",
      "    - F1 score (test): 0.14302\n",
      "clf_name='NN':\n",
      "  - Node2Vec:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.14500\n",
      "    - F1 score (test): 0.12486\n",
      "  - Text:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.54400\n",
      "    - F1 score (test): 0.52698\n",
      "  - Node2Vec + Text:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.16300\n",
      "    - F1 score (test): 0.14050\n",
      "clf_name='RF':\n",
      "  - Node2Vec:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.13900\n",
      "    - F1 score (test): 0.12345\n",
      "  - Text:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.57800\n",
      "    - F1 score (test): 0.57035\n",
      "  - Node2Vec + Text:\n",
      "    - Accuracy (train): 1.00000\n",
      "    - F1 score (train): 1.00000\n",
      "    - Accuracy (test): 0.30500\n",
      "    - F1 score (test): 0.27872\n"
     ]
    }
   ],
   "source": [
    "def print_results(clf, X_train, y_train, X_test, y_test):\n",
    "    model = clf().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    acc, f1 = evaluate(y_train, y_pred)\n",
    "    print(f\"    - Accuracy (train): {acc:.5f}\")\n",
    "    print(f\"    - F1 score (train): {f1:.5f}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc, f1 = evaluate(y_test, y_pred)\n",
    "    print(f\"    - Accuracy (test): {acc:.5f}\")\n",
    "    print(f\"    - F1 score (test): {f1:.5f}\")\n",
    "\n",
    "\n",
    "# Mistake 3: Accuracy should be at least 65%\n",
    "#            which is not stated in the question...\n",
    "clfs = {\"SVM\": LinearSVC, \"NN\": MLPClassifier, \"RF\": RandomForestClassifier}\n",
    "\n",
    "for clf_name, clf in clfs.items():\n",
    "    print(f\"{clf_name=}:\")\n",
    "    train_mask = data.train_mask.detach().cpu().numpy()\n",
    "    test_mask = data.test_mask.detach().cpu().numpy()\n",
    "    X_train = data.x[train_mask].detach().cpu().numpy()\n",
    "    y_train = data.y[train_mask].detach().cpu().numpy()\n",
    "    X_test = data.x[test_mask].detach().cpu().numpy()\n",
    "    y_test = data.y[test_mask].detach().cpu().numpy()\n",
    "    \n",
    "    # node2vec\n",
    "    model = clf().fit(node_embeddings[train_mask], y_train)\n",
    "    print(\"  - Node2Vec:\")\n",
    "    print_results(\n",
    "        clf,\n",
    "        node_embeddings[train_mask],\n",
    "        y_train,\n",
    "        node_embeddings[test_mask],\n",
    "        y_test,\n",
    "    )\n",
    "    \n",
    "    # text\n",
    "    print(\"  - Text:\")\n",
    "    print_results(clf, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # node2vec + text\n",
    "    X_train_all = np.concatenate((X_train, node_embeddings[train_mask]), axis=1)\n",
    "    X_test_all = np.concatenate((X_test, node_embeddings[test_mask]), axis=1)\n",
    "    \n",
    "    print(\"  - Node2Vec + Text:\")\n",
    "    print_results(clf, X_train_all, y_train, X_test_all, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd5054",
   "metadata": {},
   "source": [
    "#### QUESTION 25: Idea 3\n",
    "We can find the personalized PageRank of each document in seven different runs, one per class. In each run, select one of the classes and take the 20 seed documents of that class. Then, perform a random walk with the following customized properties: (a) teleportation takes the random walker to one of the seed documents of that class (with a uniform probability of 1/20 per seed document). Vary the teleportation probability in {0, 0.1, 0.2}. (b) the probability of transitioning to neighbors is not uniform among the neighbors. Rather, it is proportional to the cosine similarity between the text features of the current node and the next neighboring node. Particularly, assume we are currently visiting a document x0 which has neighbors x1, x2, x3.\n",
    "\n",
    "Then the probability of transitioning to each neighbor is:\n",
    "$$\n",
    "p_i = \\frac{\\exp(x_0\\cdot x_i)}\n",
    "{\\exp(x_0\\cdot x_1) + \\exp(x_0\\cdot x2) + \\exp(x_0\\cdot x_3)}\\text{; for i = 1, 2, 3.}\n",
    "$$\n",
    "Repeat part b for every teleportation probability in part a. Run the PageRank only on the GCC. for each seed node, do 1000 random walks. Maintain a class-wise visited frequency count for every unlabeled node. The predicted class for that unlabeled node is the class which lead to maximum visits to that node. Report accuracy and f1 scores.\n",
    "\n",
    "For example if node ’n’ was visited by 7 random walks from class A, 6 random walks from class B... 1 random walk from class G, then the predicted label of node of ’n’ is class A.\n",
    "\n",
    "> Ans: The accuracy and f1 (macro) scores are shown in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a3e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seed nodes: 140\n",
      "Number of seed nodes in GCC: 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060096b064b74adcb19837ba93143ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teleportation Probability: 0\n",
      "  - Accuracy: 0.20100\n",
      "  - F1 score: 0.18606\n",
      "Number of seed nodes: 140\n",
      "Number of seed nodes in GCC: 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c166f1d0ca495ba455aa80592c110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teleportation Probability: 0.1\n",
      "  - Accuracy: 0.62900\n",
      "  - F1 score: 0.63472\n",
      "Number of seed nodes: 140\n",
      "Number of seed nodes in GCC: 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88dda5836294c7ca420609b280552f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teleportation Probability: 0.2\n",
      "  - Accuracy: 0.63400\n",
      "  - F1 score: 0.64491\n"
     ]
    }
   ],
   "source": [
    "def run_personalized_pagerank(graph, p_teleportation):\n",
    "    # get gcc nodes\n",
    "    sorted_ccs = sorted(nx.connected_components(graph), key=len, reverse=True)\n",
    "    gcc_nodes = set(graph.subgraph(sorted_ccs[0]).nodes)\n",
    "\n",
    "    # aggregate seeds by class\n",
    "    train_idxs = np.arange(len(data.x))[data.train_mask.cpu().numpy()]\n",
    "    y_numpy = data.y.cpu().numpy()\n",
    "    class2seeds = {i: [] for i in range(dataset.num_classes)}\n",
    "    print(\"Number of seed nodes:\", len(train_idxs))\n",
    "    \n",
    "    n_used = 0\n",
    "    for train_idx in train_idxs:\n",
    "        if train_idx in gcc_nodes:\n",
    "            class2seeds[y_numpy[train_idx]].append(train_idx)\n",
    "            n_used += 1\n",
    "    print(\"Number of seed nodes in GCC:\", n_used)\n",
    "    \n",
    "    # run pagerank\n",
    "    pagerank_counts = np.zeros((len(data.x), dataset.num_classes))\n",
    "    steps = 1000\n",
    "    \n",
    "    for class_, seeds in tqdm(class2seeds.items()):\n",
    "        for seed in seeds:\n",
    "            cur = seed\n",
    "            pagerank_counts[cur][class_] += 1\n",
    "            \n",
    "            for _ in range(steps):\n",
    "                neighbors = list(graph.neighbors(cur))\n",
    "                \n",
    "                if random.random() < p_teleportation or len(neighbors) == 0:\n",
    "                    cur = random.choice(seeds)\n",
    "                    pagerank_counts[cur][class_] += 1\n",
    "                    neighbors = list(graph.neighbors(cur))\n",
    "                \n",
    "                p_sample = torch.softmax(\n",
    "                    (data.x[cur] * data.x[neighbors]).sum(dim=1), dim=0\n",
    "                )\n",
    "                cur = random.choices(neighbors, weights=p_sample)[0]\n",
    "                pagerank_counts[cur][class_] += 1\n",
    "    \n",
    "    # make predictions\n",
    "    y_pred = np.argmax(pagerank_counts, axis=1)\n",
    "    \n",
    "    # evaluate\n",
    "    test_mask = data.test_mask.cpu().numpy()\n",
    "    y_test = data.y[test_mask].cpu().numpy()\n",
    "    acc, f1 = evaluate(y_test, y_pred[test_mask])\n",
    "    print(f\"Teleportation Probability: {p_teleportation}\")\n",
    "    print(f\"  - Accuracy: {acc:.5f}\")\n",
    "    print(f\"  - F1 score: {f1:.5f}\")\n",
    "\n",
    "\n",
    "# Mistake 4: Accuracy should be at least 30% for p=0, while 70% otherwise\n",
    "#            which is also not stated in the question...\n",
    "p_teleportations = [0, 0.1, 0.2]\n",
    "\n",
    "for p_teleportation in p_teleportations:\n",
    "    run_personalized_pagerank(G, p_teleportation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
